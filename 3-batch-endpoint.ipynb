{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. RoseTTAFold on Azure ML - Batch Endpoint\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Azure is collaborating with the Baker Lab to expose their RoseTTAFold model as a service. This document describes how to get started exploring RoseTTAFold on Azure Machine Learning (Azure ML).\n",
    "\n",
    "**This is notebook #2 of 3**. In this notebook, we'll create a Batch Endpoint so that this can be called from the Azure CLI or as a REST call..\n",
    "\n",
    "In *first* notebook, [1-setup-workspace.ipynb](1-setup-workspace.ipynb), we ran some one-time setup steps to prepare our Azure ML Workspace with the dependency Datasets and a Compute Cluster.\n",
    "\n",
    "In the *second* notebook, [2-run-experiment.ipynb](2-run-experiment.ipynb) we specified some amino acid sequence data and run a RoseTTAFold job in your Azure Machine Learning workspace.\n",
    "\n",
    "**Note.** This RoseTTAFold endpoint is not designed to run in production environments, and is strictly for non-production test environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azureml.core import Workspace\n",
    "\n",
    "try:\n",
    "    ws = Workspace.from_config()\n",
    "    print(ws.name, ws.location, ws.resource_group, ws.location, sep='\\t')\n",
    "\n",
    "    # Set environment variables\n",
    "    os.environ['AZUREML_SUBSCRIPTION_ID'] = ws.subscription_id\n",
    "    os.environ['AZUREML_RESOURCE_GROUP'] = ws.resource_group\n",
    "    os.environ['AZUREML_WORKSPACE_NAME'] = ws.name\n",
    "\n",
    "    print('Azure ML workspace loaded')\n",
    "except:\n",
    "    print('Azure ML workspace not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from azureml.core import Environment\n",
    "\n",
    "env = Environment(name=\"rosettaenv\")\n",
    "env.docker.base_image = None\n",
    "env.docker.base_dockerfile = \"./Dockerfile\"\n",
    "env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_name=\"placeholdermodel\",\n",
    "                       model_path=\"placeholdermodel\",\n",
    "                       workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! az version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove old versions of the Azure ML extension \n",
    "# (Note: if these are not installed, this will print an error that you can ignore)\n",
    "! az extension remove -n azure-cli-ml\n",
    "! az extension remove -n ml\n",
    "\n",
    "# Install the latest Azure ML extension\n",
    "! az extension add -n ml -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your active Azure subscription in the Azure CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! az login\n",
    "! az configure --defaults group=%AZUREML_RESOURCE_GROUP% workspace=%AZUREML_WORKSPACE_NAME%\n",
    "! az account set --subscription %AZUREML_SUBSCRIPTION_ID%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Delete a previous endpoint with the same name, if one exists\n",
    "! az ml batch-endpoint delete --name rosetta-endpoint  --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! az ml batch-endpoint create --name rosettafold-endpoint\n",
    "! az ml batch-deployment create --file batch-deployment.yml --set-default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage\n",
    "\n",
    "The endpoint is designed to process input files containing protein sequences of the form:\n",
    "\n",
    "```\n",
    ">T1078 Tsp1, Trichoderma virens, 138 residues|\n",
    "MAAPTPADKSMMAAVPEWTITNLKRVCNAGNTSCTWTFGVDTHLATATSCTYVVKANANASQASGGPVTCGPYTITSSWSGQFGPNNGFTTFAVTDFSKKLIVWPAYTDVQVQAGKVVSPNQSYAPANLPLEHHHHHH\n",
    "```\n",
    "\n",
    "**Note.** Each input should be provided in its own input file. The input file name will be used to identify the corresponding output, so use unique input names.\n",
    "\n",
    "\n",
    "#### Call endpoint with single local file\n",
    "\n",
    "```\n",
    "az ml endpoint invoke --name rosettafold --type batch â€“input-local-path <local/path/to>/input.fa\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! az ml batch-endpoint invoke --name rosettafold-endpoint --input-local-path ./inputs/my-sequence.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Call endpoint with single remote file\n",
    "\n",
    "Given a single input file stored in Azure Blob Storage, grab the corresponding URL: `https://<storage-account-name>.blob.core.windows.net/<storage-container>/<path/on/container>/input.fa`, invoke the endpoint with:\n",
    "\n",
    "```\n",
    "az ml endpoint invoke --name rosettafold --type batch --input-path https://<storage-account-name>.blob.core.windows.net/<storage-container>/<path/on/container>/input.fa\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! az ml batch-endpoint invoke --name rosettafold-endpoint --input-path file:https://amsaiedws3295876841.blob.core.windows.net/azureml-blobstore-febe82a7-da37-4f81-85d5-48c8a0082e47/rosetta/input_samples/inputs.fa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call the endpoint with multiple files\n",
    "\n",
    "Run this exactly as above, only now pointing to a directory containing multiple files e.g.\n",
    "\n",
    "```\n",
    "az ml endpoint invoke --name rosettafold --type batch --input-path https://<storage-account-name>.blob.core.windows.net/<storage-container>/<path/on/container>/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! az ml batch-endpoint invoke --name rosettafold-endpoint --input-path folder:https://<storage-account-name>.blob.core.windows.net/<storage-container>/<path/on/container>/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Reading output\n",
    "\n",
    "When the inferencing job is complete, output files will be uploaded to the workspace default Azure Blob Storage account with the following location:\n",
    "\n",
    "```\n",
    "https://<default-storage-account>.blob.core.windows.net/<default-container>/azureml/<run-id>/score/<input-filename>/t000.e2e.pdb\n",
    "```\n",
    "\n",
    "### Configuring Parallelism\n",
    "\n",
    "When setting up the endpoint we configured the instance count, and the minibatch size parameters. These control the how the inference jobs will scale up.\n",
    "\n",
    "- Instance count: the maximum number of nodes (VMs) that will spin up.\n",
    "- Minibatch size: the maximum number of examples that will be processed at a time per-node.\n",
    "A minibatch is sent to each instance, where it will be processed sequentially. Once that node completes its minibatch it will be sent another (assuming there are any remaining inputs to be processed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REST Endpoint\n",
    "\n",
    "Batch endpoints can also be invoked via a REST endpoint as follows. Here is an example.\n",
    "\n",
    "1.\tGet batch endpoint scoring uri:\n",
    "```\n",
    "scoring_uri=$(az ml endpoint show --name rosettafold --type batch --query scoring_uri -o tsv)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get batch endpoint scoring uri:\n",
    "! scoring_uri=$(az ml endpoint show --name rosettafold --type batch --query scoring_uri -o tsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tGet authentication token:\n",
    "```\n",
    "auth_token=$(az account get-access-token --resource https://ml.azure.com --query accessToken -o tsv)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Get authentication token:\n",
    "! auth_token=$(az account get-access-token --resource https://ml.azure.com --query accessToken -o tsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tKick off inferencing job via CURL:\n",
    "\n",
    "```\n",
    "curl --location --request POST \"$scoring_uri\" --header \"Authorization: Bearer $auth_token\" --header \"Content-Type: application/json\" --data-raw \"{'properties': {'dataset': {'dataInputType': 'DataUrl', 'Path': 'https://amsaiedws3295876841.blob.core.windows.net/azureml-blobstore-febe82a7-da37-4f81-85d5-48c8a0082e47/rosetta/input_samples/inputs.fa'}}}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Kick off inferencing job via CURL:\n",
    "! curl --location --request POST \"$scoring_uri\" --header \"Authorization: Bearer $auth_token\" --header \"Content-Type: application/json\" --data-raw \"{'properties': {'dataset': {'dataInputType': 'DataUrl', 'Path': 'https://amsaiedws3295876841.blob.core.windows.net/azureml-blobstore-febe82a7-da37-4f81-85d5-48c8a0082e47/rosetta/input_samples/inputs.fa'}}}\"\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2e927916db59292ac726eb420cad9da96b7b0d3a98e037f3f33f956183ca5cf2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
